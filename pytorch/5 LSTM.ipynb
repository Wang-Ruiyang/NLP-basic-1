{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 20]) torch.Size([4, 3, 20]) torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=4)\n",
    "X = torch.randn(10, 3, 100)       # 一个句子10个单词，送进去3条句子，每个单词用一个100维的vector表示\n",
    "out, (h_n, c_n) = lstm(X)\n",
    "print(out.shape, h_n.shape, c_n.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.8368e-02, -4.1126e-04, -5.8868e-02, -3.2964e-02,  1.4120e-02,\n          -4.7668e-02, -1.5838e-02,  4.8270e-02,  2.2404e-02, -4.1941e-02,\n          -1.9616e-02, -1.7813e-02, -8.6861e-02, -2.7224e-02,  6.8505e-02,\n           3.8289e-02, -8.8780e-02, -4.1401e-02,  3.3371e-02, -1.4062e-02],\n         [ 1.8224e-02, -1.3267e-05, -5.9060e-02, -3.2871e-02,  1.3553e-02,\n          -4.6836e-02, -1.6258e-02,  4.8142e-02,  2.2594e-02, -4.1784e-02,\n          -1.9516e-02, -1.7391e-02, -8.6209e-02, -2.6872e-02,  6.8792e-02,\n           3.7712e-02, -8.8662e-02, -4.1273e-02,  3.3494e-02, -1.4386e-02],\n         [ 1.8635e-02, -1.0398e-05, -5.7922e-02, -3.3481e-02,  1.5866e-02,\n          -4.6833e-02, -1.5050e-02,  4.9025e-02,  2.1558e-02, -4.3071e-02,\n          -1.9062e-02, -1.7835e-02, -8.5562e-02, -2.6165e-02,  6.7884e-02,\n           3.6023e-02, -8.9319e-02, -4.1004e-02,  3.4693e-02, -1.3583e-02]],\n\n        [[ 2.9072e-02,  2.0472e-03, -7.2441e-02, -3.7136e-02,  1.0711e-02,\n          -7.0736e-02, -2.5466e-02,  7.2842e-02,  2.7393e-02, -6.3046e-02,\n          -2.7722e-02, -3.9020e-02, -1.4542e-01, -4.3200e-02,  9.9512e-02,\n           6.6470e-02, -1.3113e-01, -6.8676e-02,  5.8494e-02, -1.8588e-02],\n         [ 2.8702e-02,  4.1290e-03, -7.2049e-02, -3.6951e-02,  9.6878e-03,\n          -6.9119e-02, -2.6970e-02,  7.2396e-02,  2.7479e-02, -6.3848e-02,\n          -2.6803e-02, -3.8336e-02, -1.4352e-01, -4.1051e-02,  1.0010e-01,\n           6.4904e-02, -1.3003e-01, -6.7245e-02,  5.8628e-02, -1.9136e-02],\n         [ 3.0394e-02,  3.7934e-03, -6.9813e-02, -3.8502e-02,  1.5010e-02,\n          -6.9405e-02, -2.4376e-02,  7.4349e-02,  2.5541e-02, -6.6020e-02,\n          -2.6893e-02, -3.9043e-02, -1.4262e-01, -3.9927e-02,  9.8006e-02,\n           6.1209e-02, -1.3147e-01, -6.6322e-02,  6.1274e-02, -1.7305e-02]],\n\n        [[ 3.5408e-02,  1.2076e-03, -7.1379e-02, -3.3105e-02,  4.2951e-03,\n          -8.0684e-02, -2.9961e-02,  8.5100e-02,  2.8031e-02, -7.2268e-02,\n          -3.0944e-02, -5.4203e-02, -1.8184e-01, -5.1947e-02,  1.1510e-01,\n           8.5846e-02, -1.5205e-01, -8.8252e-02,  7.1117e-02, -1.7828e-02],\n         [ 3.4297e-02,  6.0003e-03, -7.0533e-02, -3.3332e-02,  2.9939e-03,\n          -7.9106e-02, -3.3034e-02,  8.5705e-02,  2.7986e-02, -7.4622e-02,\n          -2.7843e-02, -5.5003e-02, -1.7829e-01, -4.9143e-02,  1.1442e-01,\n           8.4741e-02, -1.4993e-01, -8.6197e-02,  7.2345e-02, -1.8681e-02],\n         [ 3.6833e-02,  4.9436e-03, -6.7573e-02, -3.6127e-02,  1.1628e-02,\n          -7.8832e-02, -2.8961e-02,  8.8083e-02,  2.5568e-02, -7.7203e-02,\n          -2.9790e-02, -5.4821e-02, -1.7730e-01, -4.6956e-02,  1.1209e-01,\n           7.8502e-02, -1.5209e-01, -8.3659e-02,  7.6165e-02, -1.6231e-02]],\n\n        [[ 3.8866e-02, -1.8085e-03, -6.6197e-02, -2.7884e-02, -1.4108e-04,\n          -8.3729e-02, -3.1122e-02,  9.1852e-02,  2.7347e-02, -7.5279e-02,\n          -3.2158e-02, -6.3059e-02, -2.0305e-01, -5.6795e-02,  1.2318e-01,\n           9.7814e-02, -1.6353e-01, -1.0204e-01,  7.5611e-02, -1.5174e-02],\n         [ 3.8301e-02,  4.4228e-03, -6.5914e-02, -2.8559e-02, -2.8036e-03,\n          -8.3172e-02, -3.6177e-02,  9.3150e-02,  2.7691e-02, -7.9248e-02,\n          -2.6570e-02, -6.6671e-02, -1.9956e-01, -5.3669e-02,  1.2132e-01,\n           9.8966e-02, -1.5939e-01, -1.0096e-01,  7.8231e-02, -1.5937e-02],\n         [ 4.0834e-02,  3.4910e-03, -6.2285e-02, -3.2585e-02,  7.4734e-03,\n          -8.2731e-02, -3.1421e-02,  9.6027e-02,  2.4966e-02, -8.1878e-02,\n          -3.0456e-02, -6.5639e-02, -1.9872e-01, -5.0293e-02,  1.2038e-01,\n           9.0187e-02, -1.6223e-01, -9.6399e-02,  8.2322e-02, -1.3816e-02]],\n\n        [[ 3.9747e-02, -4.8806e-03, -6.1135e-02, -2.2603e-02, -5.0185e-03,\n          -8.3739e-02, -3.2646e-02,  9.5575e-02,  2.5558e-02, -7.5900e-02,\n          -3.1859e-02, -6.8112e-02, -2.1547e-01, -5.9021e-02,  1.2852e-01,\n           1.0493e-01, -1.6979e-01, -1.1215e-01,  7.5267e-02, -1.3239e-02],\n         [ 4.1355e-02,  5.6763e-04, -6.1363e-02, -2.4534e-02, -5.7566e-03,\n          -8.3971e-02, -3.6540e-02,  9.8014e-02,  2.7418e-02, -8.0227e-02,\n          -2.4788e-02, -7.3530e-02, -2.1186e-01, -5.6313e-02,  1.2452e-01,\n           1.0866e-01, -1.6447e-01, -1.1161e-01,  7.9627e-02, -1.2253e-02],\n         [ 4.2182e-02,  1.6347e-03, -5.7084e-02, -2.9443e-02,  3.3195e-03,\n          -8.4027e-02, -3.2485e-02,  1.0187e-01,  2.3542e-02, -8.3296e-02,\n          -3.0144e-02, -7.2747e-02, -2.1139e-01, -5.4077e-02,  1.2622e-01,\n           9.8703e-02, -1.6868e-01, -1.0623e-01,  8.3348e-02, -1.1639e-02]],\n\n        [[ 3.8796e-02, -6.1755e-03, -5.7121e-02, -2.0516e-02, -7.2136e-03,\n          -8.2571e-02, -3.3412e-02,  9.9052e-02,  2.4200e-02, -7.5542e-02,\n          -3.0721e-02, -7.1950e-02, -2.2211e-01, -6.0820e-02,  1.3157e-01,\n           1.0965e-01, -1.7410e-01, -1.1919e-01,  7.4897e-02, -1.2396e-02],\n         [ 4.3689e-02, -2.5336e-03, -5.6960e-02, -2.2422e-02, -6.2494e-03,\n          -8.4056e-02, -3.6136e-02,  1.0154e-01,  2.7457e-02, -7.9920e-02,\n          -2.2766e-02, -7.8708e-02, -2.1868e-01, -5.7637e-02,  1.2600e-01,\n           1.1560e-01, -1.6728e-01, -1.1821e-01,  7.9874e-02, -8.7525e-03],\n         [ 4.3181e-02, -1.0298e-03, -5.3048e-02, -2.7640e-02,  8.1296e-04,\n          -8.4648e-02, -3.2644e-02,  1.0570e-01,  2.3159e-02, -8.2528e-02,\n          -3.0067e-02, -7.7021e-02, -2.1968e-01, -5.7137e-02,  1.3035e-01,\n           1.0474e-01, -1.7272e-01, -1.1353e-01,  8.2818e-02, -1.0150e-02]],\n\n        [[ 3.8964e-02, -7.7934e-03, -5.3814e-02, -1.9467e-02, -7.3262e-03,\n          -8.1515e-02, -3.3684e-02,  1.0182e-01,  2.4584e-02, -7.4142e-02,\n          -2.9222e-02, -7.4142e-02, -2.2530e-01, -6.1583e-02,  1.3323e-01,\n           1.1242e-01, -1.7644e-01, -1.2275e-01,  7.4697e-02, -1.0744e-02],\n         [ 4.5252e-02, -5.0444e-03, -5.3469e-02, -2.0591e-02, -7.8062e-03,\n          -8.4052e-02, -3.6247e-02,  1.0352e-01,  2.7527e-02, -7.8620e-02,\n          -2.2191e-02, -8.2223e-02, -2.2288e-01, -5.9858e-02,  1.2859e-01,\n           1.2113e-01, -1.6937e-01, -1.2311e-01,  7.8701e-02, -6.7012e-03],\n         [ 4.4344e-02, -3.5031e-03, -5.0279e-02, -2.7393e-02, -2.0004e-04,\n          -8.4995e-02, -3.1769e-02,  1.0790e-01,  2.3031e-02, -8.1131e-02,\n          -3.0522e-02, -7.9909e-02, -2.2592e-01, -5.8528e-02,  1.3306e-01,\n           1.0866e-01, -1.7488e-01, -1.1900e-01,  8.2004e-02, -9.6293e-03]],\n\n        [[ 4.0251e-02, -7.3426e-03, -5.1401e-02, -2.1632e-02, -4.7434e-03,\n          -8.0700e-02, -3.2931e-02,  1.0430e-01,  2.6780e-02, -7.3029e-02,\n          -2.7665e-02, -7.6903e-02, -2.2641e-01, -6.1893e-02,  1.3367e-01,\n           1.1496e-01, -1.7756e-01, -1.2368e-01,  7.6943e-02, -9.7127e-03],\n         [ 4.6655e-02, -8.4150e-03, -5.1467e-02, -1.9812e-02, -7.5495e-03,\n          -8.3365e-02, -3.4899e-02,  1.0438e-01,  2.7138e-02, -7.7040e-02,\n          -2.3235e-02, -8.3701e-02, -2.2672e-01, -6.1407e-02,  1.3056e-01,\n           1.2396e-01, -1.7089e-01, -1.2708e-01,  7.7597e-02, -5.4705e-03],\n         [ 4.4182e-02, -4.7162e-03, -4.7901e-02, -2.6172e-02, -3.1142e-03,\n          -8.4477e-02, -3.2314e-02,  1.0878e-01,  2.2426e-02, -7.9596e-02,\n          -3.0696e-02, -8.1057e-02, -2.2947e-01, -5.8705e-02,  1.3579e-01,\n           1.1080e-01, -1.7605e-01, -1.2262e-01,  7.9673e-02, -9.9497e-03]],\n\n        [[ 4.2786e-02, -6.5154e-03, -5.0275e-02, -2.3730e-02, -3.9541e-03,\n          -8.0397e-02, -3.2266e-02,  1.0586e-01,  2.8854e-02, -7.2883e-02,\n          -2.6429e-02, -7.9594e-02, -2.2748e-01, -6.2038e-02,  1.3427e-01,\n           1.1754e-01, -1.7691e-01, -1.2448e-01,  7.8876e-02, -9.2103e-03],\n         [ 4.7170e-02, -1.1018e-02, -4.9744e-02, -1.9805e-02, -6.1019e-03,\n          -8.2227e-02, -3.3065e-02,  1.0519e-01,  2.6320e-02, -7.5664e-02,\n          -2.4324e-02, -8.4324e-02, -2.2904e-01, -6.1691e-02,  1.3154e-01,\n           1.2400e-01, -1.7241e-01, -1.2954e-01,  7.6951e-02, -4.6538e-03],\n         [ 4.3122e-02, -4.8401e-03, -4.6157e-02, -2.4834e-02, -5.3051e-03,\n          -8.2878e-02, -3.3146e-02,  1.0933e-01,  2.1151e-02, -7.9268e-02,\n          -3.0094e-02, -8.0972e-02, -2.3108e-01, -5.8084e-02,  1.3714e-01,\n           1.1151e-01, -1.7641e-01, -1.2432e-01,  7.7289e-02, -1.0335e-02]],\n\n        [[ 4.4574e-02, -5.4555e-03, -4.9682e-02, -2.5235e-02, -4.3315e-03,\n          -8.0193e-02, -3.1341e-02,  1.0696e-01,  2.9752e-02, -7.3285e-02,\n          -2.5632e-02, -8.1888e-02, -2.2843e-01, -6.2254e-02,  1.3447e-01,\n           1.1981e-01, -1.7582e-01, -1.2587e-01,  7.9946e-02, -9.1608e-03],\n         [ 4.7687e-02, -1.3244e-02, -4.8687e-02, -2.0302e-02, -3.6358e-03,\n          -8.0741e-02, -3.0625e-02,  1.0591e-01,  2.6495e-02, -7.4444e-02,\n          -2.5182e-02, -8.4084e-02, -2.2998e-01, -6.2584e-02,  1.3237e-01,\n           1.2313e-01, -1.7405e-01, -1.2999e-01,  7.6723e-02, -3.7884e-03],\n         [ 4.1808e-02, -4.7265e-03, -4.5896e-02, -2.3648e-02, -7.3185e-03,\n          -8.1630e-02, -3.4675e-02,  1.0900e-01,  2.0307e-02, -7.9522e-02,\n          -2.9025e-02, -8.1010e-02, -2.3198e-01, -5.7075e-02,  1.3692e-01,\n           1.1230e-01, -1.7572e-01, -1.2613e-01,  7.5381e-02, -1.1024e-02]]],\n       grad_fn=<StackBackward>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20]) torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell = nn.LSTMCell(input_size=100, hidden_size=20)\n",
    "x = torch.randn(10, 3, 100)\n",
    "h = torch.zeros(3,20)\n",
    "c = torch.zeros(3,20)\n",
    "\n",
    "for xt in x:\n",
    "    h, c = cell(xt, [h,c])\n",
    "\n",
    "print(h.shape, c.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20]) torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell1 = nn.LSTMCell(input_size=100, hidden_size=30)\n",
    "cell2 = nn.LSTMCell(input_size=30, hidden_size=20)\n",
    "\n",
    "x = torch.randn(10, 3, 100)\n",
    "\n",
    "h1 = torch.zeros(3, 30)\n",
    "c1 = torch.zeros(3, 30)\n",
    "\n",
    "h2 = torch.zeros(3,20)\n",
    "c2 = torch.zeros(3,20)\n",
    "\n",
    "for xt in x:\n",
    "    h1, c1 = cell1(xt, [h1,c1])\n",
    "    h2, c2 = cell2(h1, [h2,c2])\n",
    "\n",
    "print(h2.shape, c2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "dtype = torch.FloatTensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "sentence = (\n",
    "    'GitHub Actions makes it easy to automate all your software workflows '\n",
    "    'from continuous integration and delivery to issue triage and more'\n",
    ")    # 实际上是一句话\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(list(set(sentence.split())))}\n",
    "idx2word = {i: w for i, w in enumerate(list(set(sentence.split())))}\n",
    "\n",
    "n_class = len(word2idx)\n",
    "max_len = len(sentence.split())\n",
    "\n",
    "n_hidden = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n",
      "(21, 19)\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "def make_data(sentence):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    words = sentence.split()\n",
    "\n",
    "    for i in range(max_len-1):\n",
    "        input = [word2idx[w] for w in words[:(i+1)]]     # (i+1)位置取不到\n",
    "        input = input + [0] * (max_len - len(input))\n",
    "        print(np.eye(n_class)[input].shape)\n",
    "        print(len(input))\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        target = word2idx[words[i+1]]\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return torch.Tensor(input_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "input_batch, target_batch = make_data(sentence)\n",
    "dataset = Data.TensorDataset(input_batch, target_batch)\n",
    "dataloader = Data.DataLoader(dataset, 16 ,True)     # 中间参数是batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        # input_size表示每个词用input_size维的vector表示\n",
    "        self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, bidirectional=True)\n",
    "        self.fc = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: [batch_size, max_len, n_class]\n",
    "        batch_size = X.shape[0]\n",
    "        # input: [max_len, batch_size, n_class]\n",
    "        input = X.transpose(0,1)\n",
    "        # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        hidden_state = torch.randn(1*2, batch_size, n_hidden)\n",
    "        # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        cell_state = torch.randn(1*2, batch_size, n_hidden)\n",
    "\n",
    "        outputs, (_,_) = self.lstm(input, (hidden_state, cell_state))\n",
    "        # outputs: [batch_size, n_hidden * 2]\n",
    "        outputs = outputs[-1]\n",
    "        # model: [batch_size, n_class]\n",
    "        model = self.fc(outputs)\n",
    "\n",
    "        return model\n",
    "\n",
    "modol = BiLSTM()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modol.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
